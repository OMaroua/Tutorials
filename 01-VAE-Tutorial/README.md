# ğŸ¨ Variational Autoencoders (VAEs) Tutorial

## ğŸ“– **Overview**

This tutorial provides a comprehensive introduction to **Variational Autoencoders (VAEs)**, one of the most important generative models in deep learning. You'll learn the theory behind VAEs and implement one from scratch using PyTorch.

---

## ğŸ¯ **Learning Objectives**

By the end of this tutorial, you will be able to:

- âœ… Understand the mathematical foundation of VAEs
- âœ… Implement the encoder and decoder networks
- âœ… Apply the reparameterization trick
- âœ… Compute and optimize the VAE loss (reconstruction + KL divergence)
- âœ… Generate new samples from the latent space
- âœ… Visualize and explore the latent space representation
- âœ… Apply VAEs to real datasets (MNIST, Fashion-MNIST, etc.)

---

## ğŸ“š **What You'll Learn**

### 1. **VAE Theory**
- Traditional autoencoders vs. variational autoencoders
- Probabilistic interpretation
- The Evidence Lower Bound (ELBO)
- Latent space distributions

### 2. **Implementation**
- Building the encoder (recognition model)
- Building the decoder (generative model)
- Reparameterization trick for backpropagation
- Loss function implementation

### 3. **Training & Evaluation**
- Training loop with PyTorch
- Monitoring reconstruction quality
- KL divergence balancing
- Generating new samples

### 4. **Advanced Topics**
- Conditional VAEs (CVAE)
- Î²-VAE for disentangled representations
- Applications in computer vision and healthcare

---

## ğŸ› ï¸ **Prerequisites**

**Required Knowledge:**
- Python programming
- Basic neural networks
- PyTorch fundamentals
- Probability and statistics (Gaussian distributions, KL divergence)

**Required Software:**
- Python 3.8+
- PyTorch 2.0+
- Jupyter Notebook

---

## ğŸ“¦ **Installation**

```bash
# Navigate to this tutorial folder
cd 01-VAE-Tutorial

# Install requirements
pip install -r requirements.txt

# Launch Jupyter Notebook
jupyter notebook VAE_Tutorial.ipynb
```

---

## ğŸ“ **Folder Structure**

```
01-VAE-Tutorial/
â”‚
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ VAE_Tutorial.ipynb          # Main tutorial notebook
â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ vae_model.py           # VAE model implementation
â”‚   â”œâ”€â”€ train.py               # Training script
â”‚   â””â”€â”€ utils.py               # Helper functions
â”‚
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ vae_architecture.png   # Architecture diagram
â”‚   â”œâ”€â”€ latent_space.png       # Latent space visualization
â”‚   â””â”€â”€ generated_samples.png  # Generated images
â”‚
â””â”€â”€ data/
    â””â”€â”€ README.md              # Data information
```

---

## ğŸš€ **Quick Start**

### Option 1: Interactive Notebook (Recommended)
```bash
jupyter notebook VAE_Tutorial.ipynb
```

### Option 2: Run Training Script
```bash
python src/train.py --dataset mnist --epochs 50 --latent-dim 20
```

---

## ğŸ“Š **Datasets Used**

- **MNIST**: Handwritten digits (28x28 grayscale)
- **Fashion-MNIST**: Clothing items (28x28 grayscale)
- **CelebA**: Celebrity faces (optional, for advanced section)

All datasets are automatically downloaded via PyTorch's `torchvision`.

---

## ğŸ”¬ **Key Concepts Covered**

### VAE Loss Function
```python
loss = reconstruction_loss + Î² * kl_divergence
```

Where:
- **Reconstruction Loss**: Measures how well the decoder reconstructs the input
- **KL Divergence**: Regularizes the latent space to follow a standard normal distribution
- **Î²**: Balancing parameter (Î²-VAE)

### Reparameterization Trick
```python
z = Î¼ + Ïƒ * Îµ, where Îµ ~ N(0, 1)
```

This allows gradients to flow through the stochastic sampling operation.

---

## ğŸ“ˆ **Expected Results**

After training, you should be able to:
- Generate realistic new samples
- Interpolate smoothly in latent space
- Reconstruct input images accurately
- Achieve ~100 ELBO on MNIST

---

## ğŸ“ **Further Reading**

- [Original VAE Paper](https://arxiv.org/abs/1312.6114) - Kingma & Welling (2013)
- [Î²-VAE Paper](https://openreview.net/forum?id=Sy2fzU9gl) - Higgins et al. (2017)
- [Tutorial on Variational Autoencoders](https://arxiv.org/abs/1606.05908) - Doersch (2016)

---

## ğŸ’¡ **Tips & Tricks**

1. **Start with small latent dimensions** (2-20) to visualize the latent space
2. **Balance the loss terms** - if reconstruction is poor, decrease Î²
3. **Use batch normalization** for more stable training
4. **Monitor both loss terms** separately during training

---

## ğŸ› **Common Issues**

| Issue | Solution |
|-------|----------|
| Blurry reconstructions | Try using a different loss (e.g., perceptual loss) |
| Posterior collapse | Reduce KL weight (Î²) or use KL annealing |
| Mode collapse | Increase model capacity or latent dimensions |

---

## ğŸ¤ **Contributing**

Found a bug or have a suggestion? Feel free to:
- Open an issue
- Submit a pull request
- Reach out via email

---

## ğŸ‘©â€ğŸ’» **Author**

**Maroua Oukrid**  
Computer Vision & Healthcare AI Researcher

ğŸ“§ marouaoukrid56@gmail.com  
ğŸ’¼ [LinkedIn](https://linkedin.com/in/Maroua-Oukrid)  
ğŸ± [GitHub](https://github.com/OMaroua)

---

## ğŸ“„ **License**

MIT License - Feel free to use for learning and teaching!

---

â­ **If you find this tutorial helpful, please star the repository!**

**Next Tutorial:** [Diffusion Models â†’](../02-Diffusion-Models/)

